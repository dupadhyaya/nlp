{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8b43312-b334-4047-86df-27b2814a633e",
   "metadata": {},
   "source": [
    "# bsoup \n",
    "- https://scrapeops.io/python-web-scraping-playbook/python-beautifulsoup-findall/\n",
    "- https://medium.com/ds3ucsd/web-scraping-in-15-steps-c8e295d53a9e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d7b3f6-0521-4b59-9e18-cee1fd17a565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c348593b-6bf4-4597-8cc4-41940f0ec38f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        <h1>Hello, BeautifulSoup!</h1>\n",
    "        <ul>\n",
    "            <li><a href=\"http://example.com\">Link 1</a></li>\n",
    "            <li><a href=\"http://scrapy.org\">Link 2</a></li>\n",
    "        </ul>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec30ed37-ef9c-46b6-ac0e-554b21de14fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<html>\\n    <body>\\n        <h1>Hello, BeautifulSoup!</h1>\\n        <ul>\\n            <li><a href=\"http://example.com\">Link 1</a></li>\\n            <li><a href=\"http://scrapy.org\">Link 2</a></li>\\n        </ul>\\n    </body>\\n</html>\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6de82168-705c-4988-a81f-19be3d200734",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_doc, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3db19bda-cb21-4af3-bb2d-10b13e7073db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"http://example.com\">Link 1</a>, <a href=\"http://scrapy.org\">Link 2</a>]\n"
     ]
    }
   ],
   "source": [
    "## Find All <a> Tags\n",
    "print(soup.find_all('a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f2001d-9481-4dba-9527-21cbe9bc6ec2",
   "metadata": {},
   "source": [
    "- As .find_all() returns an array of elements, you will need to loop each element in the list to extract the data you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "986365e7-4613-4e9b-b29d-95a75798d8a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link 1\n",
      "Link 2\n"
     ]
    }
   ],
   "source": [
    "element_list = soup.find_all('a')\n",
    "for element in element_list:\n",
    "    print(element.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0783036f-e024-4637-b35a-882f70f01b49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#To limit the number of results the .find_all() method returns then use the limit parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "202e6827-1b96-448a-99c5-36ea99dcb67c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"http://example.com\">Link 1</a>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a', limit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c775ad1-5a27-4a0c-8663-ca67c578c9d3",
   "metadata": {},
   "source": [
    "## FindAll By Class And Ids\n",
    "- The .find_all() method allows you to find elements on the page by class name, id, or any other element attribute using the attrs parameter.\n",
    "- tag type = p\n",
    "- class name = class_name\n",
    "- id  = id_name\n",
    "- attrs = aria-hidden-True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b82e4fc4-03ac-4ef8-a1e5-23770f5cf2ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## <p> Tag + Class Name\n",
    "soup.find_all('p', class_='class_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28d742a2-169d-4b44-be6b-7d1685bbad26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## <p> Tag + Id\n",
    "soup.find_all('p', id='id_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "527a1938-214e-494a-9052-e8f3919ad5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## <p> Tag + Any Attribute\n",
    "soup.find_all('p', attrs={\"aria-hidden\": \"true\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf2d1a6-0102-4e8e-850d-82febdc9164d",
   "metadata": {},
   "source": [
    "## Find by Text\n",
    "-  Text = Link 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4817b821-8ef3-435b-85e4-23c61eb0c7c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Link 1']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Strings that exactly match 'Link 1'\n",
    "soup.find_all(string=\"Link 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "088b419f-cb01-4f63-b2c3-c48fb8a8780c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Link 1', 'Link 2']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "## Strings that contain 'Link'\n",
    "soup.find_all(string=re.compile(\"Link\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecf284b-0957-4c9b-90f9-842019b72825",
   "metadata": {},
   "source": [
    "## Multiple Criteria\n",
    "-  If you need to find page elements that require you to add multiple attributes to the query then you can do so with the attrs parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98581249-d6b9-4442-b51e-9eaf0eac181c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## <p> Tag + Class Name & Id\n",
    "soup.find_all('p', attrs={\"class\": \"class_name\", \"id\": \"id_name\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b092c1-766a-4c19-87dc-620084a92a2c",
   "metadata": {},
   "source": [
    "## FindAll Using Regex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b216df46-fb07-418b-bd4f-e71531f9edf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for tag in soup.find_all(re.compile(\"^b\")):\n",
    "    print(tag.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a638b03c-9448-469e-ae88-a7f9bb9d28db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html\n"
     ]
    }
   ],
   "source": [
    "for tag in soup.find_all(re.compile(\"t\")):\n",
    "    print(tag.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b45aef-9e43-462a-9b32-0a6684d90277",
   "metadata": {},
   "source": [
    "## FindAll Using Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e52abb8c-8fb8-40cb-8b5d-fff7a7c3e421",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_selector(tag):\n",
    "\t# Return \"span\" tags with a class name of \"target_span\"\n",
    "\treturn tag.name == \"span\" and tag.has_attr(\"class\") and \"target_span\" in tag.get(\"class\")\n",
    "\n",
    "soup.find_all(custom_selector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b51616-66af-4019-952a-98c1cec630f4",
   "metadata": {},
   "source": [
    "## Example2\n",
    "- https://scrapeops.io/python-web-scraping-playbook/python-beautifulsoup-web-scraping/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72c77c31-ecc1-4027-ae5e-5fb2c27286ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "html_doc2 = \"\"\"<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The first paragraph</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5f9f5e9-42b7-4234-bd1f-39af9bf686b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup2 = BeautifulSoup(html_doc2, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f67e305-becc-4eee-9e95-107f3bed8d5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n"
     ]
    }
   ],
   "source": [
    "print(soup2.find('title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1d902e9-5f71-425f-89e0-87de9a3b65dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "print(soup2.find('title').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fdd054a-48fe-4eb6-83f3-bbe6043b4bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"title\"><b>The first paragraph</b></p>\n"
     ]
    }
   ],
   "source": [
    "print(soup2.find('p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9988025-4a26-49b1-a671-e960f1da890b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n"
     ]
    }
   ],
   "source": [
    "print(soup2.find_all('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8f792bde-7a98-4dcb-94ac-897ae764c7c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"title\"><b>The first paragraph</b></p>\n",
      "<b>The first paragraph</b>\n",
      "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p>\n",
      "<p class=\"story\">...</p>\n"
     ]
    }
   ],
   "source": [
    "h1b = soup2.find_all([\"p\", \"b\"])\n",
    "for element in h1b:\n",
    "  print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8772ffa2-6c92-462e-9ab5-2c8316f11ac6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## From websites\n",
    "- response.content instead of response.text as using response.text can sometimes lead to character encoding issues.\n",
    "- The .content attribute holds raw bytes, which can be decoded better than the text representation we recieve with the .text attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a592ff19-fdf1-4141-91c6-b8ce8ac5d177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get('https://quotes.toscrape.com/')\n",
    "soup3 = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebea6c5-6734-4cbe-813b-a129c58cb0e8",
   "metadata": {},
   "source": [
    "## Getting HTML Data From File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7b7baba-8e3e-4618-ae50-4d4a08f43f31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\"index1.html\") as fp:\n",
    "    soup4 = BeautifulSoup(fp, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0402d427-473d-4223-8658-c7e6cc291268",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n"
     ]
    }
   ],
   "source": [
    "print(soup4.find_all('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "593536a8-f3c6-499d-9008-5e7cabc0a3f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>The Dormouse's story</title>\n"
     ]
    }
   ],
   "source": [
    "print(soup4.find('title'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0551be9-6060-40ee-a74c-88de8e62baef",
   "metadata": {},
   "source": [
    "## Querying With Python Object Attributes\n",
    "- As BeautifulSoup converts the HTML file into a complex tree of Python objects, we can select values from within that DOM tree like we would with any other Python dictionary.\n",
    "- For example, here are some examples of querying the DOM tree of QuotesToScrape.com with object attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "003c42ab-a683-4b7a-b3b0-41f649b3debb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get('https://quotes.toscrape.com/')\n",
    "soup5 = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea4edc68-3e09-444f-bcda-92d793eb71b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Quotes to Scrape</title>\n"
     ]
    }
   ],
   "source": [
    "print(soup5.find('title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "362c94ee-f312-4893-a3b8-b3619cb4f1b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>\n",
      "<a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>\n",
      "</h1>\n"
     ]
    }
   ],
   "source": [
    "print(soup5.h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91fa8fc4-f0c9-41c1-85ab-0f690dd182e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2>Top Ten tags</h2>\n"
     ]
    }
   ],
   "source": [
    "print(soup5.h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "502fb198-3428-479d-94d4-d418ddf1a57f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Ten tags\n"
     ]
    }
   ],
   "source": [
    "print(soup5.h2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17e37e7f-bd0e-47b2-9295-004cf7900bfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>\n"
     ]
    }
   ],
   "source": [
    "print(soup5.h1.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b55f3b96-9429-4953-aabe-d1944abe7590",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quotes to Scrape\n"
     ]
    }
   ],
   "source": [
    "print(soup5.h1.a.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a51d0b9-699d-4901-a3cc-a2ec487819ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    }
   ],
   "source": [
    "print(soup5.h1.a['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12355a88-c07d-4990-ac92-1b1c92ca9c73",
   "metadata": {},
   "source": [
    "- This method works but it isn't the best as:\n",
    "- It will only return the first value it finds that matches your criteria.\n",
    "- You can't create complex queries like searching for all div tags where class='quotes'\n",
    "- As a result, it is recommended to use BeautifulSoups .find() and .find_all() methods, or use CSS Selectors via .select()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7be21ba1-1ff0-4c9e-a956-c71fd96dc2fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>\n",
      "<a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>\n",
      "</h1>\n"
     ]
    }
   ],
   "source": [
    "print(soup5.find('h1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d87d9a0-cefd-46e7-86cc-5ad3503e6e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quotes to Scrape\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup5.find('h1').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a66f4f5e-4e57-4654-8bf9-60e4b8f4c7e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    }
   ],
   "source": [
    "print(soup5.find('h1').find('a').get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cd9739-a7d8-4766-89e0-1eef6f1e450f",
   "metadata": {},
   "source": [
    "- That all looks pretty similar to querying with object attributes, however, the .find() gives us the ability to use more complex queries like searching by class, id, and other element attributes.\n",
    "- Using .find() you can create queries where two conditions or more conditions must be satisfied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68931187-d127-4668-9a3a-7a499b82c22e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## <p> Tag + Class Name\n",
    "soup5.find('p', class_='class_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e01540-0fa3-4925-acab-266cfb8a0f82",
   "metadata": {},
   "source": [
    "## Querying With CSS Selectors\n",
    "- BeautifulSoup provides a .select() method which uses the SoupSieve package to run a CSS selector against a parsed document and return all the matching elements.\n",
    "- The SoupSieve lists all the currently supported CSS selectors, however, here are some of the most commonly used:\n",
    "    - .classes\n",
    "    - #ids\n",
    "    - [attributes=value]\n",
    "    - parent child\n",
    "    - parent > child\n",
    "    - sibling ~ sibling\n",
    "    - sibling + sibling\n",
    "    - :not(element.class, element2.class)\n",
    "    - :is(element.class, element2.class)\n",
    "    - parent:has(> child)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f8fd4c8-72eb-4f06-83bf-bacf16eac812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get('https://quotes.toscrape.com/')\n",
    "soup5 = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df66d68b-acce-45fc-92fb-4bef41ad17c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quotes to Scrape\n"
     ]
    }
   ],
   "source": [
    "print(soup5.select('h1 a')[0].get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "451d1e4b-3890-43ef-bf5a-97ba2f6eb7bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"text\" itemprop=\"text\">“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”</span>, <span class=\"text\" itemprop=\"text\">“It is our choices, Harry, that show what we truly are, far more than our abilities.”</span>, <span class=\"text\" itemprop=\"text\">“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”</span>, <span class=\"text\" itemprop=\"text\">“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”</span>, <span class=\"text\" itemprop=\"text\">“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”</span>, <span class=\"text\" itemprop=\"text\">“Try not to become a man of success. Rather become a man of value.”</span>, <span class=\"text\" itemprop=\"text\">“It is better to be hated for what you are than to be loved for what you are not.”</span>, <span class=\"text\" itemprop=\"text\">“I have not failed. I've just found 10,000 ways that won't work.”</span>, <span class=\"text\" itemprop=\"text\">“A woman is like a tea bag; you never know how strong it is until it's in hot water.”</span>, <span class=\"text\" itemprop=\"text\">“A day without sunshine is like, you know, night.”</span>]\n"
     ]
    }
   ],
   "source": [
    "## Find All Quotes\n",
    "print(soup5.select('span.text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d705fee-6d4e-416f-9f67-6133f217eebe",
   "metadata": {},
   "source": [
    "- .select() Returns List\n",
    "- The .select() method returns a list of elements, so when only looking for 1 element you need to take the first element ([0]) from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c0b0324c-a50b-454d-854d-4c15755f7ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Ten tags\n"
     ]
    }
   ],
   "source": [
    "print(soup5.select('h2')[0].get_text())\n",
    "#select always returns a list, so [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca00dcc-3b79-4ab9-90aa-6d4070615ac5",
   "metadata": {},
   "source": [
    "## Aria Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7a0a5753-cc39-4936-9b95-76d326c9443d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9cbf96c7-af0b-4d11-9291-c11f8ed05300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'https://mjl.clarivate.com/search-results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "242cc4bc-9b30-4425-a635-a8184939b25f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "soup6 = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "831e0162-8c0e-46de-923e-f01c3be04922",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html lang=\"en\">\\n\\n<head>\\n  <base href=\"/\"/>\\n  <meta charset=\"UTF-8\"/>\\n  <meta name=\"'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6ae6bc66-338e-476b-b97e-8e169bd78318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup6.find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2e5e2ac2-0c0b-4223-bbc2-db9b412cae13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_tags = soup6.select('a[aria-label]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "22d16354-f098-40d3-90b6-2766a2122cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "747ec483-cfc7-4171-aed4-b31051abc6dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for tag in a_tags:\n",
    "    print(tag.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a52d3845-fea9-45e3-b64b-e026ab75bf18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_tags = soup6.findAll('a', attrs={\"aria-label\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "60453997-0aaa-48b9-8941-e79920011c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_tags = soup.findAll(lambda tag: tag.name == \"a\" and \"aria-label\" in tag.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e4900f-069a-40f9-935a-16e2a7bae7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c978c6fe-1804-4020-97a3-04f4242e72a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "html = '''\n",
    "<div id =\"119\">\n",
    "<span class=\"span\" aria-label=\"4 people reacted to this post\" role=\"button\"></span>\n",
    "</div>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cee21e93-88e6-4983-862e-39beb2bf83e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup8 = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c57a2f83-7186-4450-af7e-126875684d91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span aria-label=\"4 people reacted to this post\" class=\"span\" role=\"button\"></span>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find Span\n",
    "f = soup8.find('span')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9f83b6b3-091d-4f72-91e6-2303d5ad20b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 people reacted to this post\n"
     ]
    }
   ],
   "source": [
    "#Get aria-label attribute of Span\n",
    "print(f['aria-label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aa2296ad-9d52-4d19-844a-ee5ebb0432de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "button\n"
     ]
    }
   ],
   "source": [
    "print(f['role'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "645c3c61-b75b-4b40-95e3-e527848c1a54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4 people reacted to this post'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup8b=BeautifulSoup(html,\"lxml\")\n",
    "soup8b.find(\"span\")['aria-label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2735d985-bcc2-4353-be6f-48985b6255fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div id=\"119\">\n",
       "<span aria-label=\"4 people reacted to this post\" class=\"span\" role=\"button\"></span>\n",
       "</div>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup8b.find(\"div\", attrs ={\"id\":\"119\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "590a5865-61e1-4b06-aac4-226671df0489",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4 people reacted to this post'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup8b.find(\"div\", attrs ={\"id\":\"119\"}).find(\"span\")['aria-label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75c404e-cccd-433d-aaef-c4400e19b76d",
   "metadata": {},
   "source": [
    "## XPath in BS\n",
    "-  cannot be used\n",
    "- only lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ab44c829-6275-4521-86d0-f21742851470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9f3f5967-3aef-4f4f-b135-10ad6470bf41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get(\"https://www.scrapingbee.com/blog/\")\n",
    "soup9 = BeautifulSoup(response.content, 'html.parser')\n",
    "body = soup9.find(\"body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6da70de1-b1be-43b7-85cf-4ad94a587cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ScrapingBee Blog\n"
     ]
    }
   ],
   "source": [
    "dom = etree.HTML(str(body)) # Parse the HTML content of the page\n",
    "xpath_str = '//*[@id=\"content\"]/section/div/div[1]/h1' # The XPath expression for the blog's title\n",
    "print(dom.xpath(xpath_str)[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1759fc85-9937-499f-a893-54908044bbaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link: / Text: None\n",
      "Link: https://app.scrapingbee.com/account/login Text: Login\n",
      "Link: https://app.scrapingbee.com/account/register Text: Sign Up\n",
      "Link: /#pricing Text: Pricing\n",
      "Link: /#faq Text: FAQ\n",
      "Link: /blog/ Text: Blog\n",
      "Link: # Text: Other Features\n",
      "Link: /features/ai-web-scraping-api/ Text: AI Web Scraping\n",
      "Link: /features/screenshot/ Text: Screenshots\n",
      "Link: /features/google/ Text: Google search API\n",
      "Link: /features/data-extraction/ Text: Data extraction\n",
      "Link: /features/javascript-scenario/ Text: JavaScript scenario\n",
      "Link: /features/make/ Text: No code web scraping\n",
      "Link: # Text: Developers\n",
      "Link: /tutorials Text: Tutorials\n",
      "Link: /documentation/ Text: Documentation\n",
      "Link: https://help.scrapingbee.com/en/ Text: Knowledge Base\n",
      "Link: /blog/web-scraping-without-getting-blocked/ Text: None\n",
      "Link: /blog/web-scraping-101-with-python/ Text: None\n",
      "Link: /blog/web-scraping-javascript/ Text: None\n",
      "Link: /blog/web-scraping-r/ Text: None\n",
      "Link: /blog/web-scraping-c++/ Text: None\n",
      "Link: /blog/web-scraping-csharp/ Text: None\n",
      "Link: /blog/web-scraping-php/ Text: None\n",
      "Link: /blog/web-scraping-scala/ Text: None\n",
      "Link: /java-webscraping-book/ Text: None\n",
      "Link: /blog/web-scraping-ruby/ Text: None\n",
      "Link: /blog/web-scraping-go/ Text: None\n",
      "Link: /blog/web-scraping-elixir/ Text: None\n",
      "Link: /blog/web-scraping-rust/ Text: None\n",
      "Link: /blog/web-scraping-perl/ Text: None\n",
      "Link: /blog/no-code-web-scraping/ Text: None\n",
      "Link: /blog/no-code-competitor-monitoring/ Text: None\n",
      "Link: /blog/google-ads-competitor-analysis-system/ Text: None\n",
      "Link: /blog/how-to-easily-scrape-shopify-stores-with-ai/ Text: None\n",
      "Link: /blog/free-ai-powered-proxy-scraper-for-getting-fresh-public-proxies/ Text: None\n",
      "Link: /blog/web-scraping-go/ Text: None\n",
      "Link: /blog/introduction-to-web-scraping-with-java/ Text: None\n",
      "Link: /blog/how-download-files-via-curl-tutorial-with-examples/ Text: None\n",
      "Link: /blog/topic-analysis-of-us-state-subreddits-using-ai/ Text: None\n",
      "Link: /blog/how-to-web-scrape-in-excel/ Text: None\n",
      "Link: /blog/best-python-web-scraping-libraries/ Text: None\n",
      "Link: /blog/api-for-dummies-learning-api/ Text: None\n",
      "Link: /blog/playwright-vs-selenium/ Text: None\n",
      "Link: /blog/how-to-make-pythons-beautiful-soup-faster-performance/ Text: None\n",
      "Link: /blog/bypass-error-1005-access-denied-you-have-been-banned/ Text: None\n",
      "Link: /blog/funniest-us-states-on-reddit/ Text: None\n",
      "Link: /blog/puppeteer-stealth-tutorial-with-examples/ Text: None\n",
      "Link: /blog/ Text: 1\n",
      "Link: /blog/page/2/ Text: 2\n",
      "Link: /blog/page/3/ Text: 3\n",
      "Link: /blog/page/4/ Text: 4\n",
      "Link: /blog/page/5/ Text: 5\n",
      "Link: /blog/page/6/ Text: 6\n",
      "Link: /blog/page/7/ Text: 7\n",
      "Link: /blog/page/8/ Text: 8\n",
      "Link: /blog/page/9/ Text: 9\n",
      "Link: /blog/page/10/ Text: 10\n",
      "Link: /blog/page/11/ Text: 11\n",
      "Link: /blog/page/2/ Text: None\n",
      "Link: https://app.scrapingbee.com/account/register Text: Try ScrapingBee for Free\n",
      "Link: / Text: None\n",
      "Link: https://twitter.com/ScrapingBee Text: None\n",
      "Link: https://www.linkedin.com/company/scrapingbee Text: None\n",
      "Link: /#about-us Text: Team\n",
      "Link: /journey-to-one-million-arr/ Text: Company's journey\n",
      "Link: /blog/ Text: Blog\n",
      "Link: /rebranding/ Text: Rebranding\n",
      "Link: /affiliates/ Text: Affiliate Program\n",
      "Link: /curl-converter/ Text: Curl converter\n",
      "Link: /terms-and-conditions/ Text: Terms of Service\n",
      "Link: /privacy-policy/ Text: Privacy Policy\n",
      "Link: /gdpr/ Text: GDPR Compliance\n",
      "Link: /data-processing-agreement/ Text: Data Processing Agreement\n",
      "Link: /cookie-policy/ Text: Cookie Policy\n",
      "Link: /acceptable-use-policy/ Text: Acceptable Use Policy\n",
      "Link: /legal-notices/ Text: Legal Notices\n",
      "Link: /#features Text: Features\n",
      "Link: /#pricing Text: Pricing\n",
      "Link: https://status.scrapingbee.com Text: Status\n",
      "Link: /crawlera-alternative/ Text: Alternative to Crawlera\n",
      "Link: /luminati-alternative/ Text: Alternative to Luminati\n",
      "Link: /netnut-alternative/ Text: Alternative to NetNut\n",
      "Link: /scraperapi-alternative/ Text: Alternative to ScraperAPI\n",
      "Link: /scrapingbee-alternative/ Text: Alternatives to ScrapingBee\n",
      "Link: /blog/no-code-web-scraping/ Text: No code web scraping\n",
      "Link: /blog/no-code-competitor-monitoring/ Text: No code competitor monitoring\n",
      "Link: /blog/scrape-content-google-sheet/ Text: How to put scraped website data into Google Sheets\n",
      "Link: /blog/no-code-stock-price-slack/ Text: Send stock prices update to Slack\n",
      "Link: /blog/nocode-amazon/ Text: Scrape Amazon products' price with no code\n",
      "Link: /blog/nocode-amazon/ Text: Scrape Amazon products' price with no code\n",
      "Link: /blog/no-code-job-data-extraction/ Text: Extract job listings, details and salaries\n",
      "Link: /webscraping-questions/ Text: Web scraping questions\n",
      "Link: /blog/web-scraping-without-getting-blocked/ Text: A guide to Web Scraping without getting blocked\n",
      "Link: /blog/web-scraping-tools/ Text: Web Scraping Tools\n",
      "Link: /blog/best-free-proxy-list-web-scraping/ Text: Best Free Proxies\n",
      "Link: /blog/best-mobile-4g-proxy-provider-webscraping/ Text: Best Mobile proxies\n",
      "Link: /blog/scraping-vs-crawling/ Text: Web Scraping vs Web Crawling\n",
      "Link: /blog/rotating-proxies/ Text: Rotating and residential proxies\n",
      "Link: /blog/web-scraping-101-with-python/ Text: Web Scraping with Python\n",
      "Link: /blog/web-scraping-php/ Text: Web Scraping with PHP\n",
      "Link: /blog/introduction-to-web-scraping-with-java/ Text: Web Scraping with Java\n",
      "Link: /blog/web-scraping-ruby/ Text: Web Scraping with Ruby\n",
      "Link: /blog/web-scraping-javascript/ Text: Web Scraping with NodeJS\n",
      "Link: /blog/web-scraping-r/ Text: Web Scraping with R\n",
      "Link: /blog/web-scraping-csharp/ Text: Web Scraping with C#\n",
      "Link: /blog/web-scraping-c++/ Text: Web Scraping with C++\n",
      "Link: /blog/web-scraping-elixir/ Text: Web Scraping with Elixir\n",
      "Link: /blog/web-scraping-perl/ Text: Web Scraping with Perl\n",
      "Link: /blog/web-scraping-rust/ Text: Web Scraping with Rust\n",
      "Link: /blog/web-scraping-go/ Text: Web Scraping with Go\n"
     ]
    }
   ],
   "source": [
    "#All Links\n",
    "links = soup9.find_all(\"a\") # Find all elements with the tag <a>\n",
    "for link in links:\n",
    "  print(\"Link:\", link.get(\"href\"), \"Text:\", link.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3465c644-e8e4-4c1e-8793-b470598abe14",
   "metadata": {},
   "source": [
    "## Sibling in BS\n",
    "- find_previous_sibling to find the single previous sibling\n",
    "- find_next_sibling to find the single next sibling\n",
    "- find_all_next to find all the next siblings\n",
    "- find_all_previous to find all previous siblings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8a5aacd1-58fc-407e-99af-c595bc17dcda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "html_content = '''\n",
    "<p>First paragraph</p>\n",
    "<p>Second Paragraph</p>\n",
    "<p id=\"main\">Main Paragraph</p>\n",
    "<p>Fourth Paragraph</p>\n",
    "<p>Fifth Pragaraph</p>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bdcae05c-49c5-4273-af44-7e8da7bc6714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup10 = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "19f72b25-2717-4da8-a3b4-d25ef530b324",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"main\">Main Paragraph</p>\n"
     ]
    }
   ],
   "source": [
    "main_element = soup10.find(\"p\", attrs={\"id\": \"main\"})\n",
    "print(main_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5edfd4d8-ea6e-41d2-a824-fa73334bcca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Second Paragraph</p>\n"
     ]
    }
   ],
   "source": [
    "# Find the previous sibling:\n",
    "print(main_element.find_previous_sibling())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a1279f06-d128-4e03-a294-611994ef6034",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Fourth Paragraph</p>\n",
      "[<p>Fourth Paragraph</p>, <p>Fifth Pragaraph</p>]\n",
      "[<p>Second Paragraph</p>, <p>First paragraph</p>]\n"
     ]
    }
   ],
   "source": [
    "# Find the next sibling:\n",
    "print(main_element.find_next_sibling())\n",
    "\n",
    "# Find all next siblings:\n",
    "print(main_element.find_all_next())\n",
    "\n",
    "# Find all previous siblings:\n",
    "print(main_element.find_all_previous())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e914ab-0d12-4f85-9aab-acbe395e936c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a7b4a4a6-e3ac-4285-87e3-c88d1ed0179e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link: / Text: None\n",
      "Link: https://app.scrapingbee.com/account/login Text: Login\n",
      "Link: https://app.scrapingbee.com/account/register Text: Sign Up\n",
      "Link: /#pricing Text: Pricing\n",
      "Link: /#faq Text: FAQ\n",
      "Link: /blog/ Text: Blog\n",
      "Link: # Text: Other Features\n",
      "Link: /features/ai-web-scraping-api/ Text: AI Web Scraping\n",
      "Link: /features/screenshot/ Text: Screenshots\n",
      "Link: /features/google/ Text: Google search API\n",
      "Link: /features/data-extraction/ Text: Data extraction\n",
      "Link: /features/javascript-scenario/ Text: JavaScript scenario\n",
      "Link: /features/make/ Text: No code web scraping\n",
      "Link: # Text: Developers\n",
      "Link: /tutorials Text: Tutorials\n",
      "Link: /documentation/ Text: Documentation\n",
      "Link: https://help.scrapingbee.com/en/ Text: Knowledge Base\n",
      "Link: /blog/web-scraping-without-getting-blocked/ Text: None\n",
      "Link: /blog/web-scraping-101-with-python/ Text: None\n",
      "Link: /blog/web-scraping-javascript/ Text: None\n",
      "Link: /blog/web-scraping-r/ Text: None\n",
      "Link: /blog/web-scraping-c++/ Text: None\n",
      "Link: /blog/web-scraping-csharp/ Text: None\n",
      "Link: /blog/web-scraping-php/ Text: None\n",
      "Link: /blog/web-scraping-scala/ Text: None\n",
      "Link: /java-webscraping-book/ Text: None\n",
      "Link: /blog/web-scraping-ruby/ Text: None\n",
      "Link: /blog/web-scraping-go/ Text: None\n",
      "Link: /blog/web-scraping-elixir/ Text: None\n",
      "Link: /blog/web-scraping-rust/ Text: None\n",
      "Link: /blog/web-scraping-perl/ Text: None\n",
      "Link: /blog/no-code-web-scraping/ Text: None\n",
      "Link: /blog/no-code-competitor-monitoring/ Text: None\n",
      "Link: /blog/google-ads-competitor-analysis-system/ Text: None\n",
      "Link: /blog/how-to-easily-scrape-shopify-stores-with-ai/ Text: None\n",
      "Link: /blog/free-ai-powered-proxy-scraper-for-getting-fresh-public-proxies/ Text: None\n",
      "Link: /blog/web-scraping-go/ Text: None\n",
      "Link: /blog/introduction-to-web-scraping-with-java/ Text: None\n",
      "Link: /blog/how-download-files-via-curl-tutorial-with-examples/ Text: None\n",
      "Link: /blog/topic-analysis-of-us-state-subreddits-using-ai/ Text: None\n",
      "Link: /blog/how-to-web-scrape-in-excel/ Text: None\n",
      "Link: /blog/best-python-web-scraping-libraries/ Text: None\n",
      "Link: /blog/api-for-dummies-learning-api/ Text: None\n",
      "Link: /blog/playwright-vs-selenium/ Text: None\n",
      "Link: /blog/how-to-make-pythons-beautiful-soup-faster-performance/ Text: None\n",
      "Link: /blog/bypass-error-1005-access-denied-you-have-been-banned/ Text: None\n",
      "Link: /blog/funniest-us-states-on-reddit/ Text: None\n",
      "Link: /blog/puppeteer-stealth-tutorial-with-examples/ Text: None\n",
      "Link: /blog/ Text: 1\n",
      "Link: /blog/page/2/ Text: 2\n",
      "Link: /blog/page/3/ Text: 3\n",
      "Link: /blog/page/4/ Text: 4\n",
      "Link: /blog/page/5/ Text: 5\n",
      "Link: /blog/page/6/ Text: 6\n",
      "Link: /blog/page/7/ Text: 7\n",
      "Link: /blog/page/8/ Text: 8\n",
      "Link: /blog/page/9/ Text: 9\n",
      "Link: /blog/page/10/ Text: 10\n",
      "Link: /blog/page/11/ Text: 11\n",
      "Link: /blog/page/2/ Text: None\n",
      "Link: https://app.scrapingbee.com/account/register Text: Try ScrapingBee for Free\n",
      "Link: / Text: None\n",
      "Link: https://twitter.com/ScrapingBee Text: None\n",
      "Link: https://www.linkedin.com/company/scrapingbee Text: None\n",
      "Link: /#about-us Text: Team\n",
      "Link: /journey-to-one-million-arr/ Text: Company's journey\n",
      "Link: /blog/ Text: Blog\n",
      "Link: /rebranding/ Text: Rebranding\n",
      "Link: /affiliates/ Text: Affiliate Program\n",
      "Link: /curl-converter/ Text: Curl converter\n",
      "Link: /terms-and-conditions/ Text: Terms of Service\n",
      "Link: /privacy-policy/ Text: Privacy Policy\n",
      "Link: /gdpr/ Text: GDPR Compliance\n",
      "Link: /data-processing-agreement/ Text: Data Processing Agreement\n",
      "Link: /cookie-policy/ Text: Cookie Policy\n",
      "Link: /acceptable-use-policy/ Text: Acceptable Use Policy\n",
      "Link: /legal-notices/ Text: Legal Notices\n",
      "Link: /#features Text: Features\n",
      "Link: /#pricing Text: Pricing\n",
      "Link: https://status.scrapingbee.com Text: Status\n",
      "Link: /crawlera-alternative/ Text: Alternative to Crawlera\n",
      "Link: /luminati-alternative/ Text: Alternative to Luminati\n",
      "Link: /netnut-alternative/ Text: Alternative to NetNut\n",
      "Link: /scraperapi-alternative/ Text: Alternative to ScraperAPI\n",
      "Link: /scrapingbee-alternative/ Text: Alternatives to ScrapingBee\n",
      "Link: /blog/no-code-web-scraping/ Text: No code web scraping\n",
      "Link: /blog/no-code-competitor-monitoring/ Text: No code competitor monitoring\n",
      "Link: /blog/scrape-content-google-sheet/ Text: How to put scraped website data into Google Sheets\n",
      "Link: /blog/no-code-stock-price-slack/ Text: Send stock prices update to Slack\n",
      "Link: /blog/nocode-amazon/ Text: Scrape Amazon products' price with no code\n",
      "Link: /blog/nocode-amazon/ Text: Scrape Amazon products' price with no code\n",
      "Link: /blog/no-code-job-data-extraction/ Text: Extract job listings, details and salaries\n",
      "Link: /webscraping-questions/ Text: Web scraping questions\n",
      "Link: /blog/web-scraping-without-getting-blocked/ Text: A guide to Web Scraping without getting blocked\n",
      "Link: /blog/web-scraping-tools/ Text: Web Scraping Tools\n",
      "Link: /blog/best-free-proxy-list-web-scraping/ Text: Best Free Proxies\n",
      "Link: /blog/best-mobile-4g-proxy-provider-webscraping/ Text: Best Mobile proxies\n",
      "Link: /blog/scraping-vs-crawling/ Text: Web Scraping vs Web Crawling\n",
      "Link: /blog/rotating-proxies/ Text: Rotating and residential proxies\n",
      "Link: /blog/web-scraping-101-with-python/ Text: Web Scraping with Python\n",
      "Link: /blog/web-scraping-php/ Text: Web Scraping with PHP\n",
      "Link: /blog/introduction-to-web-scraping-with-java/ Text: Web Scraping with Java\n",
      "Link: /blog/web-scraping-ruby/ Text: Web Scraping with Ruby\n",
      "Link: /blog/web-scraping-javascript/ Text: Web Scraping with NodeJS\n",
      "Link: /blog/web-scraping-r/ Text: Web Scraping with R\n",
      "Link: /blog/web-scraping-csharp/ Text: Web Scraping with C#\n",
      "Link: /blog/web-scraping-c++/ Text: Web Scraping with C++\n",
      "Link: /blog/web-scraping-elixir/ Text: Web Scraping with Elixir\n",
      "Link: /blog/web-scraping-perl/ Text: Web Scraping with Perl\n",
      "Link: /blog/web-scraping-rust/ Text: Web Scraping with Rust\n",
      "Link: /blog/web-scraping-go/ Text: Web Scraping with Go\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5192373-d2fe-4c06-b9e9-9b4795d88b26",
   "metadata": {},
   "source": [
    "## Tables\n",
    "-  We can parse a table's content with BeautifulSoup by finding all <tr> elements, and finding their <td> or <th> children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2d8865a1-1e9b-49f2-889c-44cc997f925d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get(\"https://demo.scrapingbee.com/table_content.html\")\n",
    "soup11 = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ad6fc0b2-beb1-420d-b367-b03ad750c6ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "table = soup11.find('table')\n",
    "table_body = table.find('tbody')\n",
    "#table_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "630938b9-5359-45f1-9f63-83c16025b687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows = table.find_all('tr')\n",
    "for row in rows:\n",
    "    cols = row.find_all(['td', 'th'])\n",
    "    cols = [ele.text.strip() for ele in cols]\n",
    "    data.append([ele for ele in cols if ele])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5e4ad3fa-b098-4a62-a308-23822f33cdd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['SYMBOL', 'NAME', 'PRICE', 'CHANGE', '%CHANGE'], ['AMD', 'Advanced Micro Devices Inc', '89.48', '-5.34', '-5.63'], ['ADBE', 'Adobe Inc.', '378.07', '-15.76', '-4'], ['ABNB', 'Airbnb Inc', '99.91', '-9.01', '-8.27'], ['ALGN', 'Align Technology Inc', '247.75', '-9.3', '-3.62'], ['AMZN', 'Amazon.com Inc', '103.87', '-5.78', '-5.27'], ['AMGN', 'Amgen Inc', '237.7', '-2.31', '-0.96'], ['AEP', 'American Electric Power Company Inc', '95.24', '-3.02', '-3.07'], ['ADI', 'Analog Devices Inc', '150.32', '-6.6', '-4.21'], ['ANSS', 'ANSYS Inc', '232.21', '-9.66', '-3.99'], ['AAPL', 'Apple Inc', '133.98', '-3.15', '-2.3'], ['AMAT', 'Applied Materials Inc', '96.48', '-5.4', '-5.3'], ['ASML', 'ASML Holding NV', '497.48', '-24.05', '-4.61'], ['TEAM', 'Atlassian Corporation PLC', '167.46', '-16.35', '-8.9'], ['ADSK', 'Autodesk Inc', '175.43', '-11.65', '-6.23'], ['ATVI', 'Activision Blizzard Inc', '75.39', '-1.09', '-1.43'], ['ADP', 'Automatic Data Processing Inc', '208', '-3.62', '-1.71'], ['AZN', 'AstraZeneca PLC', '60.09', '-1.7', '-2.75'], ['AVGO', 'Broadcom Inc', '523.73', '-17.54', '-3.24'], ['BIDU', 'Baidu Inc', '133.44', '-9.43', '-6.6'], ['BIIB', 'Biogen Inc', '192.89', '-4.61', '-2.34'], ['BMRN', 'Biomarin Pharmaceutical Inc', '72.4', '-2.68', '-3.57'], ['BKNG', 'Booking Holdings Inc', '1,953', '-151.96', '-7.22'], ['CDNS', 'Cadence Design Systems Inc', '143.12', '-5.99', '-4.02'], ['CHTR', 'Charter Communications Inc', '466.19', '-8.01', '-1.69'], ['CPRT', 'Copart Inc', '105.06', '-3.24', '-2.99'], ['CRWD', 'CrowdStrike Holdings Inc', '153.73', '-15.59', '-9.21'], ['CTAS', 'Cintas Corp', '360.82', '-13.94', '-3.72'], ['CSCO', 'Cisco Systems Inc', '43.4', '-0.09', '-0.2'], ['CMCSA', 'Comcast Corp', '40.77', '-0.86', '-2.08'], ['COST', 'Costco Wholesale Corp', '455.3', '-8.01', '-1.73'], ['CSX', 'CSX Corp', '29.71', '-0.59', '-1.95'], ['CTSH', 'Cognizant Technology Solutions Corp', '69.22', '-0.69', '-0.99'], ['DDOG', 'Datadog Inc', '87.82', '-8.38', '-8.71'], ['DOCU', 'DocuSign Inc', '58.77', '-7.16', '-10.86'], ['DXCM', 'Dexcom Inc', '69.11', '-4.35', '-5.92'], ['DLTR', 'Dollar Tree Inc', '154.74', '-1.26', '-0.81'], ['EA', 'Electronic Arts', '130.02', '-3.42', '-2.56'], ['EBAY', 'eBay Inc', '43.14', '-1.14', '-2.57'], ['EXC', 'Exelon Corp', '44.57', '-1.44', '-3.13'], ['FAST', 'Fastenal Co', '50.51', '-1.47', '-2.83'], ['META', 'Meta Platforms Inc', '168.15', '-7.42', '-4.23'], ['FISV', 'Fiserv Inc', '90.97', '-3.37', '-3.57'], ['FTNT', 'Fortinet Inc', '270.54', '-17.77', '-6.16'], ['GILD', 'Gilead Sciences Inc', '59.53', '-1.21', '-1.99'], ['GOOG', 'Alphabet Class C', '2,167.52', '-61.03', '-2.74'], ['GOOGL', 'Alphabet Class A', '2,154.78', '-68.45', '-3.08'], ['HON', 'Honeywell International Inc', '184.35', '-1.93', '-1.04'], ['ILMN', 'Illumina Inc', '196.02', '-8.17', '-4'], ['INTC', 'Intel Corp', '38.26', '-0.92', '-2.35'], ['INTU', 'Intuit Inc', '367.09', '-14.13', '-3.71'], ['ISRG', 'Intuitive Surgical Inc', '196.61', '-8.66', '-4.22'], ['MRVL', 'Marvell Technology Inc', '49.03', '-4.03', '-7.6'], ['IDXX', 'IDEXX Laboratories Inc', '335.78', '-10.1', '-2.92'], ['JD', 'JD.Com Inc', '58.94', '-2.57', '-4.18'], ['KDP', 'Keurig Dr Pepper Inc', '35.23', '-0.26', '-0.73'], ['KLAC', 'KLA Corp', '316.38', '-17.28', '-5.18'], ['KHC', 'Kraft Heinz Co', '36.77', '-0.68', '-1.83'], ['LRCX', 'Lam Research Corp', '449.71', '-24.7', '-5.21'], ['LCID', 'Lucid Group Inc', '16.65', '-1.37', '-7.61'], ['LULU', 'Lululemon Athletica Inc', '276.36', '-15.24', '-5.23'], ['MELI', 'Mercadolibre Inc', '629.28', '-62.41', '-9.02'], ['MAR', 'Marriott International Inc', '152.7', '-7.17', '-4.48'], ['MTCH', 'Match Group Inc', '72.51', '-4.17', '-5.44'], ['MCHP', 'Microchip Technology Inc', '60.66', '-3.49', '-5.44'], ['MDLZ', 'Mondelez International Inc', '60.04', '-0.76', '-1.25'], ['MRNA', 'Moderna Inc', '118.53', '-8.59', '-6.76'], ['MNST', 'Monster Beverage Corp', '84.73', '-2.31', '-2.65'], ['MSFT', 'Microsoft Corp', '246.11', '-6.88', '-2.72'], ['MU', 'Micron Technology Inc', '59.06', '-3.56', '-5.69'], ['NFLX', 'Netflix Inc', '172.3', '-10.64', '-5.82'], ['NTES', 'NetEase Inc', '100.8', '-4.86', '-4.6'], ['NVDA', 'NVIDIA Corp', '159.06', '-10.68', '-6.29'], ['NXPI', 'NXP Semiconductors NV', '171.99', '-6.58', '-3.68'], ['OKTA', 'Okta Inc', '82.52', '-7.6', '-8.43'], ['ODFL', 'Old Dominion Freight Line Inc', '241.42', '-5.76', '-2.33'], ['ORLY', 'O’Reilly Automotive Inc', '602.54', '-4.9', '-0.81'], ['PCAR', 'Paccar Inc', '84.25', '-0.85', '-1'], ['PANW', 'Palo Alto Networks Inc', '476.74', '-18.48', '-3.73'], ['PAYX', 'Paychex Inc', '118.05', '-2.58', '-2.14'], ['PDD', 'Pinduoduo Inc', '53.69', '-6.26', '-10.44'], ['PYPL', 'PayPal Holdings Inc', '75.01', '-4.29', '-5.41'], ['PEP', 'PepsiCo Inc.', '162.55', '+0.03', '+0.02'], ['QCOM', 'Qualcomm Inc', '128.92', '-4.28', '-3.21'], ['REGN', 'Regeneron Pharmaceuticals Inc', '554.64', '-17.16', '-3'], ['ROST', 'Ross Stores Inc', '75.17', '-2.03', '-2.63'], ['SIRI', 'Sirius XM Holdings Inc', '6.03', '-0.07', '-1.15'], ['SGEN', 'Seagen Inc', '136.25', '-3.14', '-2.26'], ['SPLK', 'Splunk Inc', '89.72', '-8.73', '-8.87'], ['SWKS', 'Skyworks Solutions Inc', '93.97', '-6.28', '-6.26'], ['SBUX', 'Starbucks Corp', '72.72', '-2.95', '-3.9'], ['SNPS', 'Synopsys Inc', '292.22', '-13.17', '-4.31'], ['TSLA', 'Tesla Inc', '660.93', '-35.76', '-5.13'], ['TXN', 'Texas Instruments Inc', '155.16', '-2.62', '-1.66'], ['TMUS', 'T-Mobile US Inc', '127.85', '-2.66', '-2.04'], ['VRSN', 'Verisign Inc', '164.31', '-4.79', '-2.83'], ['VRSK', 'Verisk Analytics Inc', '161.68', '-2.42', '-1.47'], ['VRTX', 'Vertex Pharmaceuticals Inc', '247.82', '-7.06', '-2.77'], ['WBA', 'Walgreens Boots Alliance Inc', '40.67', '-0.87', '-2.09'], ['WDAY', 'Workday Inc', '142', '-7.27', '-4.87'], ['XEL', 'Xcel Energy Inc', '69.53', '-1.48', '-2.08'], ['ZM', 'Zoom Video Communications Inc', '103.26', '-5.81', '-5.33'], ['ZS', 'Zscaler Inc', '142.04', '-11.57', '-7.53']]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bcfb413a-85e5-4084-9b6a-a433a54232a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8936b608-e673-4ab0-9441-2737f203fc6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>NAME</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>CHANGE</th>\n",
       "      <th>%CHANGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMD</td>\n",
       "      <td>Advanced Micro Devices Inc</td>\n",
       "      <td>89.48</td>\n",
       "      <td>-5.34</td>\n",
       "      <td>-5.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADBE</td>\n",
       "      <td>Adobe Inc.</td>\n",
       "      <td>378.07</td>\n",
       "      <td>-15.76</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABNB</td>\n",
       "      <td>Airbnb Inc</td>\n",
       "      <td>99.91</td>\n",
       "      <td>-9.01</td>\n",
       "      <td>-8.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALGN</td>\n",
       "      <td>Align Technology Inc</td>\n",
       "      <td>247.75</td>\n",
       "      <td>-9.3</td>\n",
       "      <td>-3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com Inc</td>\n",
       "      <td>103.87</td>\n",
       "      <td>-5.78</td>\n",
       "      <td>-5.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SYMBOL                        NAME   PRICE  CHANGE %CHANGE\n",
       "0    AMD  Advanced Micro Devices Inc   89.48   -5.34   -5.63\n",
       "1   ADBE                  Adobe Inc.  378.07  -15.76      -4\n",
       "2   ABNB                  Airbnb Inc   99.91   -9.01   -8.27\n",
       "3   ALGN        Align Technology Inc  247.75    -9.3   -3.62\n",
       "4   AMZN              Amazon.com Inc  103.87   -5.78   -5.27"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data[1:], columns=data[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ae600e-ee39-4732-b9e6-ded300648c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
