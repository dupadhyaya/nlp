{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed9dd1ce",
   "metadata": {},
   "source": [
    "# BERT Score\n",
    "-  BERTScore is an automatic evaluation metric for text generation that computes a similarity score for each token in the candidate sentence with each token in the reference sentence. It leverages the pre-trained contextual embeddings from BERT models and matches words in candidate and reference sentences by cosine similarity.\n",
    "-  BERTScore takes 3 mandatory arguments : \n",
    "    -  predictions (a list of string of candidate sentences), \n",
    "    -  references (a list of strings or list of list of strings of reference sentences) and \n",
    "    -  either lang (a string of two letters indicating the language of the sentences, in ISO 639-1 format) or model_type (a string specififying which model to use, according to the BERT specification). The default behavior of the metric is to use the suggested model for the target language when one is specified, otherwise to use the model_type indicated.\n",
    "-  https://huggingface.co/spaces/evaluate-metric/bertscore\n",
    "-  https://paperswithcode.com/paper/bertscore-evaluating-text-generation-with\n",
    "-  https://www.geeksforgeeks.org/explanation-of-bert-model-nlp/\n",
    "-  https://www.techtarget.com/searchenterpriseai/definition/BERT-language-model\n",
    "-  https://colab.research.google.com/drive/1kpL8Y_AnUUiCxFjhxSrxCsc6-sDMNb_Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561b2395",
   "metadata": {},
   "source": [
    "## under progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b64227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install evaluate\n",
    "#!pip install bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62dba95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")\n",
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "382e6281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0fe791705540f18203ac93b1adf898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54be60ea545d4c8cb11730904c2210f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad8e682242f41bb946e01a542dfebf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ece59b953b498abaf7ad99aa2df86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ac7ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad0e1bd",
   "metadata": {},
   "source": [
    "## Maximal values with the distilbert-base-uncased model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cfcd715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9550d704d0494217b3d56e4a68e46c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe8e79acc6742d6ac807e2c28e9f65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51bec86e82e4cee9fd586611554ed4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b07e17fec644b580dd53ee2972787e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from evaluate import load\n",
    "#bertscore = load(\"bertscore\")\n",
    "predictions = [\"hello world\", \"general kenobi\"]\n",
    "references = [\"hello world\", \"general kenobi\"]\n",
    "results = bertscore.compute(predictions=predictions, references=references, model_type=\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f534f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': [1.000000238418579, 1.0000001192092896], 'recall': [1.000000238418579, 1.0000001192092896], 'f1': [1.000000238418579, 1.0000001192092896], 'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=4.26.1)'}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9259333e",
   "metadata": {},
   "source": [
    "## Partial match with the distilbert-base-uncased model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "539fce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': [0.7899678945541382, 0.5584040284156799], 'recall': [0.7899678945541382, 0.5889027714729309], 'f1': [0.7899678349494934, 0.573248028755188], 'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=4.26.1)'}\n"
     ]
    }
   ],
   "source": [
    "#from evaluate import load\n",
    "#bertscore = load(\"bertscore\")\n",
    "predictions = [\"hello world\", \"general kenobi\"]\n",
    "references = [\"goodnight moon\", \"the sun is shining\"]\n",
    "results = bertscore.compute(predictions=predictions, references=references, model_type=\"distilbert-base-uncased\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf7bad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49808096",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "-  The original BERTScore paper showed that BERTScore correlates well with human judgment on sentence-level and system-level evaluation, but this depends on the model and language pair selected.\n",
    "-  calculating the BERTScore metric involves downloading the BERT model that is used to compute the score-- the default model for en, roberta-large, takes over 1.4GB of storage space and downloading it can take a significant amount of time depending on the speed of your internet connection. If this is an issue, choose a smaller model; for instance distilbert-base-uncased is 268MB. A full list of compatible models can be found here.\n",
    "-  https://docs.google.com/spreadsheets/d/1RKOVpselB98Nnh_EOC4A2BYn8_201tmPODpNWu4w7xI/edit#gid=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff18716",
   "metadata": {},
   "source": [
    "##  Example\n",
    "-  https://torchmetrics.readthedocs.io/en/stable/text/bert_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7c96d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from torchmetrics.text.bert import BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19a32756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchmetrics\\text\\bert.py:179: UserWarning: The argument `model_name_or_path` was not specified while it is required when the default `transformers` model is used. It will use the default recommended model - 'roberta-large'.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b3a06da1f149b09113508fd69d4676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bertscore2 = BERTScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c16a183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [\"hello there\", \"general kenobi\"]\n",
    "target = [\"hello there\", \"master kenobi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a415c648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': [0.9999998807907104, 0.9960543513298035],\n",
      " 'precision': [0.9999998807907104, 0.9960543513298035],\n",
      " 'recall': [0.9999998807907104, 0.9960543513298035]}\n"
     ]
    }
   ],
   "source": [
    "pprint(bertscore2(preds, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5292acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.text.bert import BERTScore\n",
    "preds = [\"hello there\", \"general kenobi\"]\n",
    "target = [\"hello there\", \"master kenobi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68f4b45",
   "metadata": {},
   "source": [
    "metric = BERTScore()\n",
    "metric.update(preds, target)\n",
    "fig_, ax_ = metric.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39eb39f",
   "metadata": {},
   "source": [
    "## X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00286ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#pip install google  #to install Google Search by Mario Vilas see\n",
    "#https://python-googlesearch.readthedocs.io/en/latest/\n",
    "import googlesearch  #Scrap serps\n",
    "#to randomize pause\n",
    "import random\n",
    "import time  #to calcute page time download\n",
    "from datetime import date      \n",
    "import sys #for sys variables\n",
    " \n",
    "import requests #to read urls contents\n",
    "from bs4 import BeautifulSoup  #to decode html\n",
    "from bs4.element import Comment\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04cc5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove comments and non visible tags from html\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
